name: Update GFS Zarr

on:
  schedule:
    - cron: '30 3,9,15,21 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    env:
      GIT_LFS_SKIP_SMUDGE: 1
    steps:
      - name: Free up disk space
        run: |
          echo "Before cleanup:"
          df -h
          # Remove large unnecessary packages (~40GB freed)
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/share/swift
          sudo rm -rf /usr/local/.ghcup
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          sudo docker image prune --all --force
          sudo apt-get clean
          # Remove apt caches
          sudo apt-get autoremove -y
          sudo rm -rf /var/lib/apt/lists/*
          echo "After cleanup:"
          df -h

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libeccodes0 libeccodes-dev git-lfs

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Configure capture window
        run: |
          FH=$(python - <<'PY'
          # 209 forecast hours: 1-hourly to 120h, then 3-hourly to 384h
          early = list(range(0, 121, 1))
          late = list(range(123, 385, 3))
          print(' '.join(str(x) for x in early + late))
          PY
          )
          echo "FORECAST_HOURS=${FORECAST_HOURS:-$FH}" >> $GITHUB_ENV
          echo "GRID=${GRID:-0p25}" >> $GITHUB_ENV
          echo "PARAM_SHORTNAMES=${PARAM_SHORTNAMES:-}" >> $GITHUB_ENV
          # Select key pressure levels to reduce size
          echo "LEVELS_HPA=${LEVELS_HPA:-1000 925 850 700 500 300 250 200 150 100 50 10}" >> $GITHUB_ENV
          echo "MAX_ZARR_BYTES=${MAX_ZARR_BYTES:-1500000000}" >> $GITHUB_ENV
          echo "DTYPE=${DTYPE:-float16}" >> $GITHUB_ENV

      - name: Prepare data worktree
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Remove any existing data worktree to start fresh
          rm -rf ../data-worktree

          # Always create fresh orphan branch (no history)
          mkdir -p ../data-worktree
          cd ../data-worktree
          git init
          git checkout --orphan data

          # Configure LFS to never download old files
          git lfs install --skip-smudge --local
          git config lfs.fetchexclude "*"

          # Re-add LFS tracking for large artifacts
          if [ -f ../Gfs_Pressure_Zarr/.gitattributes ]; then
            cp ../Gfs_Pressure_Zarr/.gitattributes .
          fi
          git lfs track "*.zarr.zip"
          git add .gitattributes

          # Set remote
          git remote add origin https://github.com/${{ github.repository }}.git

          echo "Data worktree ready (fresh repo, no history):"
          df -h

      - name: Generate Zarr archive
        run: |
          echo "=== System resources before processing ==="
          df -h
          free -h
          python scripts/update_gfs_zarr.py --output ../data-worktree/gfs_latest.zarr --zip

          echo "=== Aggressive cleanup ==="
          # Clean up GRIB downloads
          rm -rf /tmp/gfs
          # Clean up unzipped zarr (only keep .zip)
          rm -rf ../data-worktree/gfs_latest.zarr
          # Clean up Python caches
          find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
          find . -type d -name .pytest_cache -exec rm -rf {} + 2>/dev/null || true
          pip cache purge || true
          # Clean up any temp files
          rm -rf ~/.cache/* || true
          # Clean up git LFS cache (don't need old versions)
          cd ../data-worktree
          git lfs prune || true
          rm -rf .git/lfs/objects/* || true

          echo "=== System resources after processing ==="
          df -h
          free -h
          echo "=== Files in data worktree ==="
          ls -lh ../data-worktree

      - name: Commit and push latest data
        run: |
          cd ../data-worktree
          git add .gitattributes gfs_latest.zarr.zip latest_metadata.json
          git status --short
          git commit -m "Update GFS pressure levels $(date -u +'%Y-%m-%d %H:%M UTC')" || echo "No changes to commit"
          git push --force origin HEAD:data
