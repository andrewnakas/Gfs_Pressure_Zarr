name: Update GFS Zarr

on:
  schedule:
    - cron: '30 3,9,15,21 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    env:
      GIT_LFS_SKIP_SMUDGE: 1
    steps:
      - name: Free up disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          sudo apt-get clean
          echo "After cleanup:"
          df -h

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libeccodes0 libeccodes-dev git-lfs

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Configure capture window
        run: |
          FH=$(python - <<'PY'
          # Match dynamical GFS: 16 days = 384 hours
          # 3-hourly to reduce file count and disk usage
          print(' '.join(str(x) for x in range(0, 385, 3)))
          PY
          )
          echo "FORECAST_HOURS=${FORECAST_HOURS:-$FH}" >> $GITHUB_ENV
          echo "GRID=${GRID:-0p50}" >> $GITHUB_ENV
          echo "PARAM_SHORTNAMES=${PARAM_SHORTNAMES:-}" >> $GITHUB_ENV
          echo "LEVELS_HPA=${LEVELS_HPA:-}" >> $GITHUB_ENV
          echo "MAX_ZARR_BYTES=${MAX_ZARR_BYTES:-1900000000}" >> $GITHUB_ENV
          echo "DTYPE=${DTYPE:-float16}" >> $GITHUB_ENV

      - name: Prepare data worktree
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git fetch origin data || true
          if git ls-remote --exit-code origin data >/dev/null 2>&1; then
            git worktree add -B data ../data-worktree origin/data
          else
            git worktree add -b data ../data-worktree
          fi
          cd ../data-worktree
          git lfs install --skip-smudge
          find . -mindepth 1 -maxdepth 1 ! -name .git -exec rm -rf {} +
          # Re-add LFS tracking for large artifacts
          if [ -f ../Gfs_Pressure_Zarr/.gitattributes ]; then
            cp ../Gfs_Pressure_Zarr/.gitattributes .
          fi
          git lfs track "*.zarr.zip"
          git add .gitattributes

      - name: Generate Zarr archive
        run: |
          python scripts/update_gfs_zarr.py --output ../data-worktree/gfs_latest.zarr --zip
          # Clean up GRIB downloads and unzipped zarr immediately
          rm -rf /tmp/gfs
          rm -rf ../data-worktree/gfs_latest.zarr
          echo "Disk usage after Zarr generation:"
          df -h
          ls -lh ../data-worktree

      - name: Commit and push latest data
        run: |
          cd ../data-worktree
          git add .gitattributes gfs_latest.zarr.zip latest_metadata.json
          git status --short
          git commit -m "Update GFS pressure levels $(date -u +'%Y-%m-%d %H:%M UTC')" || echo "No changes to commit"
          git push --force origin HEAD:data
